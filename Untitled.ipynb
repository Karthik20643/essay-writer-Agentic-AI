{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c4b3c83d-cd8d-4b9f-8f60-b21d41d9e099",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e3abe8f4-dc71-4f01-8b88-955a0d0d746b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import StateGraph, END\n",
    "from typing import TypedDict, List\n",
    "from langchain_core.messages import SystemMessage, HumanMessage\n",
    "from pydantic import BaseModel\n",
    "from tavily import TavilyClient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0279cbc9-349d-4da2-99ff-ffe53fd674a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_ollama import ChatOllama\n",
    "\n",
    "model = ChatOllama(\n",
    "    model=\"llama3\",\n",
    "    temperature=0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7149ec68-5df6-4312-a25f-5f3a7c9c5311",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.checkpoint.memory import MemorySaver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cb48a215-df27-4dea-9248-487d75982cec",
   "metadata": {},
   "outputs": [],
   "source": [
    "memory = MemorySaver()\n",
    "tavily = TavilyClient(\n",
    "    api_key=\"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\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c073be20-a074-4385-b63d-cb6949bc7e02",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AgentState(TypedDict) : \n",
    "    task: str\n",
    "    plan: str\n",
    "    draft: str\n",
    "    critique: str\n",
    "    content: str\n",
    "    content_number: int\n",
    "    revision_no: int\n",
    "    max_revision: int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ee8256f3-668b-4230-8cfc-a9740d42bb7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "PLAN_PROMPT = \"\"\"You are an expert writer tasked with writing a high level outline of an essay. \\\n",
    "Write such an outline for the user provided topic. Give an outline of the essay along with any relevant notes \\\n",
    "or instructions for the sections.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "923df0eb-138e-474f-8707-5c84408a3d95",
   "metadata": {},
   "outputs": [],
   "source": [
    "WRITER_PROMPT = \"\"\"You are an essay assistant tasked with writing excellent 5-paragraph essays.\\\n",
    "Generate the best essay possible for the user's request and the initial outline. \\\n",
    "If the user provides critique, respond with a revised version of your previous attempts. \\\n",
    "Utilize all the information below as needed: \n",
    "\n",
    "------\n",
    "\n",
    "{content}\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f29492cc-b936-4501-b5a7-1c1d7d31953e",
   "metadata": {},
   "outputs": [],
   "source": [
    "REFLECTION_PROMPT = \"\"\"You are a teacher grading an essay submission. \\\n",
    "Generate critique and recommendations for the user's submission. \\\n",
    "Provide detailed recommendations, including requests for length, depth, style, etc.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "eb37f58a-432a-4468-bee1-02ed950c002c",
   "metadata": {},
   "outputs": [],
   "source": [
    "RESEARCH_PLAN_PROMPT = \"\"\"You are a researcher charged with providing information that can \\\n",
    "be used when writing the following essay. Generate a list of search queries that will gather \\\n",
    "any relevant information. Only generate 3 queries max.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "43b8b584-367c-46db-b4e7-8079ec866d72",
   "metadata": {},
   "outputs": [],
   "source": [
    "RESEARCH_CRITIQUE_PROMPT = \"\"\"You are a researcher charged with providing information that can \\\n",
    "be used when making any requested revisions (as outlined below). \\\n",
    "Generate a list of search queries that will gather any relevant information. Only generate 3 queries max.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f722332b-6be2-4a3b-93e1-78af14473c87",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Queries(BaseModel):\n",
    "    queries: List[str]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "351ecf73-5748-40c3-886a-91ecea66d48c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plan_node(state: AgentState):\n",
    "    \"\"\"Creates a high-level outline for the essay\"\"\"\n",
    "    messages = [\n",
    "        SystemMessage(content=PLAN_PROMPT), \n",
    "        HumanMessage(content=state['task'])\n",
    "    ]\n",
    "    response = model.invoke(messages)\n",
    "    return {\"plan\": response.content}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "68abdb51-08fb-4030-b6f3-5c08ae6d6af1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def research_plan_node(state: AgentState):\n",
    "    \"\"\"Searches the web for information based on the initial plan\"\"\"\n",
    "    queries = model.with_structured_output(Queries).invoke([\n",
    "        SystemMessage(content=RESEARCH_PLAN_PROMPT),\n",
    "        HumanMessage(content=state['task'])\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8653e6cd-b616-42ab-a46f-630d42843c32",
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_node(state, queries):\n",
    "    content = state.get(\"content\", [])\n",
    "\n",
    "    for q in queries.queries:\n",
    "        response = tavily.search(query=q, max_results=2)\n",
    "        for r in response.get(\"results\", []):\n",
    "            content.append(r[\"content\"])\n",
    "\n",
    "    return {\"content\": content}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5640df48-92c5-4cd7-a437-3a15e0e13fe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generation_node(state: AgentState):\n",
    "    \"\"\"Generates or revises the essay draft\"\"\"\n",
    "    content = \"\\n\\n\".join(state['content'] or [])\n",
    "    user_message = HumanMessage(\n",
    "        content=f\"{state['task']}\\n\\nHere is my plan:\\n\\n{state['plan']}\"\n",
    "    )\n",
    "    messages = [\n",
    "        SystemMessage(content=WRITER_PROMPT.format(content=content)),\n",
    "        user_message\n",
    "    ]\n",
    "    response = model.invoke(messages)\n",
    "    return {\n",
    "        \"draft\": response.content, \n",
    "        \"revision_number\": state.get(\"revision_number\", 1) + 1\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "afd11d2f-9d27-47dd-9587-3f966d855d71",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reflection_node(state: AgentState):\n",
    "    \"\"\"Critiques the current draft and provides feedback\"\"\"\n",
    "    messages = [\n",
    "        SystemMessage(content=REFLECTION_PROMPT), \n",
    "        HumanMessage(content=state['draft'])\n",
    "    ]\n",
    "    response = model.invoke(messages)\n",
    "    return {\"critique\": response.content}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "85e77fa3-5908-4e51-bd55-1876e8e1392e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def research_critique_node(state: AgentState):\n",
    "    \"\"\"Searches for additional information based on critique\"\"\"\n",
    "    queries = model.with_structured_output(Queries).invoke([\n",
    "        SystemMessage(content=RESEARCH_CRITIQUE_PROMPT),\n",
    "        HumanMessage(content=state['critique'])\n",
    "    ])\n",
    "    content = state['content'] or []\n",
    "    for q in queries.queries:\n",
    "        response = tavily.search(query=q, max_results=2)\n",
    "        for r in response['results']:\n",
    "            content.append(r['content'])\n",
    "    return {\"content\": content}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0c726ec7-2276-4c5e-92ab-202c3c3b6535",
   "metadata": {},
   "outputs": [],
   "source": [
    " def should_continue(state):\n",
    "    \"\"\"Decides whether to continue revising or finish\"\"\"\n",
    "    if state[\"revision_number\"] > state[\"max_revisions\"]:\n",
    "        return END\n",
    "    return \"reflect\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b8e00e8f-2110-444f-93b5-fdd1ba544043",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langgraph.graph.state.StateGraph at 0x17091733f90>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "builder = StateGraph(AgentState)\n",
    "\n",
    "# Add all nodes to the graph\n",
    "builder.add_node(\"planner\", plan_node)\n",
    "builder.add_node(\"generate\", generation_node)\n",
    "builder.add_node(\"reflect\", reflection_node)\n",
    "builder.add_node(\"research_plan\", research_plan_node)\n",
    "builder.add_node(\"research_critique\", research_critique_node)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "56737215-6a1b-44f5-9bc6-d63cca11de00",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langgraph.graph.state.StateGraph at 0x17091733f90>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "builder.set_entry_point(\"planner\")\n",
    "\n",
    "# Define the workflow edges\n",
    "builder.add_edge(\"planner\", \"research_plan\")\n",
    "builder.add_edge(\"research_plan\", \"generate\")\n",
    "builder.add_edge(\"reflect\", \"research_critique\")\n",
    "builder.add_edge(\"research_critique\", \"generate\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "5cd6585e-a998-43b1-b7cf-48539ff66f4c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langgraph.graph.state.StateGraph at 0x17091733f90>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "builder.add_conditional_edges(\n",
    "    \"generate\", \n",
    "    should_continue, \n",
    "    {END: END, \"reflect\": \"reflect\"}\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "3edc95dd-3e39-4464-a5a5-705e53581438",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = builder.compile(checkpointer=memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "3f0f1c6a-da1a-4950-a35a-b8d500ea8f8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚ö† Could not display graph: Install pygraphviz to draw graphs: `pip install pygraphviz`.\n",
      "  Install graphviz if you want to see the visualization\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    from IPython.display import Image, display\n",
    "    display(Image(graph.get_graph().draw_png()))\n",
    "    print(\"‚úì Graph visualization displayed\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ö† Could not display graph: {e}\")\n",
    "    print(\"  Install graphviz if you want to see the visualization\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c6a70a6-6c6f-40a5-966f-88dff3932e70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "STARTING ESSAY GENERATION WORKFLOW\n",
      "============================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "thread = {\"configurable\": {\"thread_id\": \"1\"}}\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"STARTING ESSAY GENERATION WORKFLOW\")\n",
    "print(\"=\"*60 + \"\\n\")\n",
    "\n",
    "for s in graph.stream(\n",
    "    {\n",
    "        \"task\": \"what is the difference between langchain and langsmith\",\n",
    "        \"max_revisions\": 2,\n",
    "        \"revision_number\": 1,\n",
    "        \"content\": [],          # ‚Üê REQUIRED\n",
    "    },\n",
    "    thread,\n",
    "):\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"Step: {list(s.keys())[0]}\")\n",
    "    print(f\"{'='*60}\")\n",
    "    print(s)\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"WORKFLOW COMPLETED\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "130aa356-7358-41d4-8a55-0839fdedb908",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_state = graph.get_state(thread)\n",
    "print(\"\\nüìù FINAL ESSAY:\\n\")\n",
    "print(final_state.values.get('draft', 'No draft available'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cffe901a-4393-47a9-9a13-468f496da79e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
